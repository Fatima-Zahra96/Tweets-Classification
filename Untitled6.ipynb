{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report ml_task : Tweet classification   |  name : Fatima Zahra Akherraz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports the modules or libreries that we gonna need in our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pn\n",
    "import re\n",
    "import csv\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import our dataset; train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train=pn.read_csv(\"train.csv\")\n",
    "dataset_test=pn.read_csv(\"test.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our data, we should clean it by removing all other characters that will not be meaningful to our machine learning algorithm that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "        text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', text)\n",
    "        text = re.sub('@[^\\s]+','USER', text)\n",
    "        text = text.lower().replace(\"ё\", \"е\")\n",
    "        text = re.sub('[^a-zA-Zа-яА-Я1-9]+',' ', text)\n",
    "        text = re.sub(' +',' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to balance classes by using the Down-sampling method.\n",
    "This method involves randomly removing rows from the majority class to prevent its signal from dominating the learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sampling(train_clean) :\n",
    "    \n",
    "    train_maj = train_clean[train_clean.Label=='Sports']\n",
    "    train_min = train_clean[train_clean.Label=='Politics']\n",
    "    train_maj_downsampled = resample(train_maj, \n",
    "                                     replace=False,  # sample without replacement\n",
    "                                     n_samples=len(train_min), # to match minority class  \n",
    "                                     random_state=123) # reproducible results\n",
    "    train_downsampled = pn.concat([train_maj_downsampled, train_min]) # Combine minority class with downsampled majority class\n",
    "    n=train_downsampled['Label'].value_counts()\n",
    "    print(n)\n",
    "    return train_upsampled; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to generat a csv file as a result of our prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file(test_clean, test_predict):\n",
    "    with open('tweets_result.csv', 'w') as csvfile:\n",
    "        file = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        file.writerow(['TweetId','Label'])\n",
    "        i=0\n",
    "        for id_tweet  in test_clean['TweetId'] :\n",
    "            file.writerow([id_tweet, test_predict[i]])\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use dataset we are going to take the number of rows and columns that we need. In our case we are going to use all rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=dataset_train.iloc[:,:]\n",
    "test=dataset_test.iloc[:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of code we clean our dataset using the functions that we defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politics    3200\n",
      "Sports      3200\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train.loc[:,'TweetText'] = [clean_tweet(t) for t in train['TweetText']]\n",
    "test.loc[:,'TweetText'] = [clean_tweet(t) for t in test['TweetText']]\n",
    "\n",
    "train_clean = train\n",
    "test_clean = test\n",
    "\n",
    "train_clean=down_sampling(train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a sci-kit learn pipeline with a SGDClassifier to create a pipeline object that will apply each step to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('nb', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to split our data (train data) to train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_clean['TweetText'],                                    \n",
    "train_clean['Label'],random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to train our data in order to get get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sports' 'Politics' 'Politics' ... 'Politics' 'Sports' 'Politics']\n",
      "(0.9575471698113207, 0.9619631901840491)\n"
     ]
    }
   ],
   "source": [
    "model = pipeline_sgd.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "sports=recall_score(y_test, y_predict, pos_label='Sports')\n",
    "politics=recall_score(y_test, y_predict, pos_label='Politics')\n",
    "\n",
    "result=sports,politics\n",
    "\n",
    "print(y_predict)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the data, we are going to predict our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test_clean['TweetText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to generate a csv file which contains our labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file(test_clean,test_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
